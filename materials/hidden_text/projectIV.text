% CMSC 423 Project IV: Clustering and classification

Posted: Nov 27, 2013
Last Update: Dec. 12, 2013
Due: Dec. 13, 2013

In this project you will use gene expression data from [this study](http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE1297) to learn about
clustering and classification

###Part I: Prepare expression data for analysis

You will find two files of data in the <directory>:

* alz_pd.csv: is a table containing information about samples
* alz_e_.csv: is a matrix of gene expression values

You can read in the sample information table using the following code:

```python
import numpy as np
import csv

# read the first line to get column names
with open('alz_pd.csv','r') as f:
     reader = csv.reader(f)
     names = reader.next()


phenoData=np.loadtxt('alz_pd.csv',delimiter=',',skiprows=1,
	dtype={'names':names,'formats': tuple(['S15' for nm in names])})
```
These are 30 samples labeled as normal hippocampus or one of three Alzheimer's severity indices (incipient, moderate or severe).
To obtain the list of labels use the following:

```python
labels=list(phenoData['SubType'])
```
You can read in the expression data using the following code:

```python
import gzip

# read the first line to get file names
with gzip.open('alz_e.csv.gz','r') as f:
     reader = csv.reader(f)
     filenames = reader.next()

exprData=np.loadtxt("alz_e.csv.gz",delimiter=',',skiprows=1)
```

Verify that your sample information data has 30 samples:

```python
phenoData.shape
```

Verify that your expression data has 22,283 gene expression measurements for 30 samples:

```python
exprData.shape
```

Verify that the columns of the expression data and the sample data coincide:

```python
np.all(filenames == phenoData['filename'])
```

In all that follows we use the following notation:

* $x_{gi}$: gene expression value for *gene* $g$, sample $i$.

The first thing to implement is a filtering procedure to reduce the number of genes under study. We will use a 
technique called *independent filtering*, which selects informative measurements (features in Machine Learning language)
that could help cluster and classify samples, without using the class (sample type) information. In this case we will median
absolute value deviation to perform filtering

**Problem 1:** Implement a function to calculate median absolute deviation for each gene, and select the 300 genes with highest median absolute deviation (MAD)

$$
mad(g) = median_i | x_{gi} - m_g |
$$

where $m_g$ is the median expression for gene $g$. Hint: use [numpy.median](http://docs.scipy.org/doc/numpy/reference/generated/numpy.median.html)
Include it in file `filtering.py`.

**Question 1:** Why is choosing genes with highest MAD a good way of selecting features? 

###Part II: Implement k-means for expression data. 

Recall the k-means algorithm presented in class

```
select k starting centroids
do
	assign samples to nearest centroid
	compute new centroids based on assignment
while any assignment changes or max number of iterations not reached
```

Write function `kmeans(x, k, maxit)` implementing this algorithm in file `kmeans.py`:

```python
def kmeans(x, k, maxit):
"""
Implementation of k means algorithm 

arguments:
	x: numpy array of gene expression
	k: number of clusters to estimate
	maxit: maximum number of iterations

returns:
	vector of cluster assignments for each column 
"""
```

Notes:  

You can select the initial set of $k$ centroids by choosing $k$ samples randomly.
There are smarter ways of doing this (see extra credit section below)

**Problem 2:** Run the k-means algorithm for values of $k$=2,3,4,5,10,15. Set maxit to 100 in each case.

**Question 2:** Discuss the result of this clustering exercise:
	 a) What is the relationship between clusters and severity of the samples (see section on data above)?  
	 b) Can you deduce from this analysis that some of these severity classes are better defined than others? Explain  

###Part III: Nearest centroid classifier

In this part you will implement a *classification* algorithm. The classification problem is a classic in Machine Learning. 

The setting is that we observe for each sample $i$ a set of $p$ features (gene expression in our case)
represented in vector $x_i$, and *qualitative* outcomes (or classes) $g_i$, which can take
values from a discrete set $G$.  In our case where our features are genomic
measurements (gene expression for now), and that we have many more features than 
samples (i.e. $p$ << $N$, where $N$ is the number of samples). For gene expression,
features are real numbers, and we can think of feature space as Euclidean space.

Since our prediction $\hat{G}(x)$ will always take values in the
discrete set $G$, we can divide the input space into a
collection of regions taking the same predicted classes.

![classification boundaries](../images/classification-plots-01.png)

The question is: what is the best sub-division of this space?
The boundaries of this partition can be smooth or rough depending
on the prediction function. For an important class of procedures, these *decision boundaries* are
linear (like the upper left plot). This is what we will refer to as linear methods for
classification. The nearest centroid classifier is one such linear method.
For genomics, linear methods are commonly used since more complicated methods
are prone to *overfit* (more on this below) data when $p$ << $N$.

In our dataset, the classes $G$ are labels (normal, incipient, moderate, severe). 
Classification algorithms are usually divided into two parts: a *training* phase where the
classifier is estimated (or learned) and a *prediction* phase where it is applied to samples to
derive classifications. The *training* algorithm to 
learn a nearest centroid classifier is very simple: compute the centroid (mean) for each class.
Implement this function as follows:

```python
def train_nearest_centroid(x, g):
"""
Train a nearest centroid classifier

arguments:
	x: a numpy array of gene expression measurements
	g: a list of class labels for each sample in x

returns:
	a numpy array of centroids (one for each label in g)
"""
```

Then the prediction phase is also very simple: given a sample $x$ select the nearest centroid and classify with the corresponding label.
Implement this function as follows:

```python
def predict_nearest_centroid(x, centroids):
"""
Predict labels using the nearest centroid classifier

arguments:
	x: a numpy array of gene expression measurements
	g: a numpy array of centroids

returns:
	a list of predicted labels for each sample in x
"""
```

**Problem 3:** Implement the nearest centroid classifier using these two functions in file `nearest_centroid.py`.  
**Question 3:** How good is the nearest centroid classifier on the alzheimer's expression dataset? Discuss this using *prediction error rate*: the percentage
of samples that are erroneously classified by the nearest centroid classifier.

In Machine Learning, classification methods are usually used for prediction purposes: for example, now that you have a classifier, use it
to predict alzheimer's severity based on gene expression measurements. And we care that these predictions are accurate for these new samples.
This concept is generally called *generalization*: you don't want to learn a classifier for these specific samples, you want a classifer that can
perform well on general sets of samples. Equivalently, we want classifiers that do not *overfit* to these specific samples.

One way of testing the *generalization* ability of a classifier is to use *resampling methods* where we simulate our prediction situation using the dataset
we are provided.  One version of this is to randomly divide the dataset in two sets: use one set to train the classifier, and use the other set to
measure the prediction error rate of the classifier on new samples (i.e., samples not used to train the classifier). This process is repeated some number of times 
to estimate the average error rate of the classifier.

**Problem 4:** Use this resampling method on the gene expression dataset to calculate average prediction error rate for the nearest centroid classifier on this dataset. Calculate
average prediction error over 50 random splits of the dataset.

**Question 4:** Is the average prediction error rate you calculate using this *resampling method* better or worse than the prediction error rate calculated in Question 3? Discuss.  
**Question 5:** What is the relationship between the $k$-mean clustering method and the nearest centroid classifier?  
**Question 6:** Discuss your expectations on the ability of the nearest centroid classifier to perform well on this data based on what you observed from the clustering exercise above.  

###Part IV: Extra credit work:

You have two opportunities for extra credit in this project

A) Implement a smarter initialization technique for $k$-means clustering. Choose the initial centroids as follows: 

```
1. choose a random sample as the i centroid
2. for i=2,...,k:
        choose centroid i as the sample with greatest average distance to centroids 1,...i-1
```

**Problem 5:** Implement this initialization method in function `kmeans2` with same specification as the `kmeans` function.
Include it in file `extracredit.py`.

**Question 7:** Compare the performance of this centroid initialization with the one presented above. You should run
these two versions of the clustering algorithms multiple times with multiple values of $k$ to answer this question.

B) Implement a "stochastic" version of $k$-means clustering. Implement a variation of the $k$-means algorithm which
doesn't assign samples to the nearest cluster as above. Instead it assigns samples to clusters randomly, such that the
probability that sample $i$ is assigned to cluster $l$ is given by

$$
P(c(i) = l | x_i) = \frac{exp\{-\|x_i - \mu_l \|^2}{\sum_{l=1}^k exp\{-\|x_i - \mu_l \|^2\}}
$$

Problem 6: Implement this algorithm in function `soft_kmeans` with same specification as the `kmeans` function.
Include it in file `extracredit.py`.

**Question 8:** Show that the above is a proper probabilty by showing that $\sum_{l=1}^k P(c(i) = l)=1$.  
**Question 9:** Compare the performance of this clustering method with the one presented above. You should run the
two clustering algorithms multiple times with multiple values of $k$ to answer this question.

###What to hand in:

Code: files `kmeans.py` and `nearest_centroid.py` along with `extracredit.py` (if applicable). Writeup: `writeup.pdf` answering questions 1-6 along
with `extracredit.pdf` for questions 7 and 8 (if applicable). Zip these files and submit as in the previous projects.

Note that grading for style includes writing clearly and completely. In this case, your writeup will be graded based on the evidence you provide (via table
or figure) to answer the questions given.



