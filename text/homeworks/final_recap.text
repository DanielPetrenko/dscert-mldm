% CMSC423: Final Recap
% Fall 2013

The final exam will consist of: ~10 quick questions (multiple choice, true/false), ~3 short questions, 2 long questions. It is cumulative, but will be skewed towards 
material covered in the last third of the class (10-14 below). As in the second midterm *some* of the questions from previous exams may reappear. 

It will cover the following material:

1.	Molecular Biology concepts. Most questions will be about term/concept identification, possibly a short question to
test your understanding of basic molecular biology processess: e.g., replication, transcription, translation.  

2.	Bioinformatics Resources. Quick questions of to check your ability to identify resources containing specific types of data. E.g., genomic sequences
may be found in refseq, sequencing experiments in the Short Read Archive  

3.	Sequencing. What makes second-generation sequencing happen. Sources of errors in sequencing data. How can we use high-throughput
sequencing data to answer specific biological questions. E.g., measuring gene expression using DNA sequencing  

4.	Matching problem formulations: exact vs. inexact matching. Why do we need inexact matching algorithms.  

5.	Exact Matching methods. I will ask you questions about properties of algorithms (running and/or space complexity), details about their implementation, and their application to specific string problems that can be solved using exact matching. The following are fair game: z-algorithm,
KMP (using z-algorithm preprocessing and the automata formulation), keyword trees, suffix tries, suffix trees.  

6. 	Exact Matching of pattern sets. The Aho-Corasick algorithm. What are keyword trees, their failure links? What are output links, and why do we need them? Complexity
of preprocessing a set of patterns (including failure and output links), and matching a target. Some of these will be from midterm 1.  

7.	Suffix Arrays. Definition, search algorithm. Space vs. search time tradeoff.  

8.	Inexact Alignment. Dynamic progamming algorithms: Global alignment (Needleman-Wunsch), Local alignment (Smith-Waterman). Linear gap penalties, affine gap penalties. The probabilistic
interpretation of scoring matrices (as log odds of two probabilistic models). Why do we need a statistical treatment of alignment scores when comparing
a query against a large database? Formulating inexact alignment algorithms as finite state machines.  

9.	Multiple Sequence Alignment. Problem formulation. The DP solution. The star algorithm and its approximation bound.  

10.	Sequence Assembly. The Hamiltonian and Eluerian approaches to sequence assembly. High-level understanding of Lander-Waterman probabilistic assembly model.    

11.	Motif finding. What are transcription factors? What are motifs? What is the motif finding problem (biologically and computationally)? What is a ``profile"? How is motif finding an instance
of the general pattern finding problem and iterative methods for discrete optimization? What is the benefit of randomly selecting a starting point for a given sequence instead of choosing the starting point that maximizes probability.  

12.   Clustering. What is the general clustering problem (assuming gene expression, or other continuous measurements/features). What is the k-means algorithm? What is the objective function minimized by the k-means algorithm? What is the soft k-means formulation and what is its' relationship with the general framework used in the motif finding problem.  

13.   Classification. What is the general classification problem (assuming gene expression, or other continuous measurements/features). What is the nearest centroid classifier? What is its relationship with the k-means algorithm? Why is the decision function/boundary for the nearest centroid classifier linear? What is unsupervised vs. supervised learning? Why should we use the Bayes Rule in probabilistic classification settings?  

14.   Phylogeny. Why do we study phylogenetic trees? What is parsimony? Why should we find parsimonious explanations to phylogenetic trees?  

